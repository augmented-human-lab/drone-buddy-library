<!DOCTYPE html>
<html  lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1"><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

      <title>Supported models</title>
    
          <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
          <link rel="stylesheet" href="_static/theme.css " type="text/css" />
      
      <!-- sphinx script_files -->
        <script src="_static/documentation_options.js?v=5929fcd5"></script>
        <script src="_static/doctools.js?v=888ff710"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>

      
      <!-- bundled in js (rollup iife) -->
      <!-- <script src="_static/theme-vendors.js"></script> -->
      <script src="_static/theme.js" defer></script>
    
  <link rel="index" title="Index" href="genindex.html" />
  <link rel="search" title="Search" href="search.html" />
  <link rel="next" title="Supported models" href="dronebuddylib.userguide.objectdetection.html" />
  <link rel="prev" title="Supported models" href="dronebuddylib.userguide.intentrecognition.html" /> 
  </head>

  <body>
    <div id="app">
    <div class="theme-container" :class="pageClasses"><navbar @toggle-sidebar="toggleSidebar">
  <router-link to="index.html" class="home-link">
    
      <span class="site-name">Dronebuddy</span>
    
  </router-link>

  <div class="links">
    <navlinks class="can-hide">



    </navlinks>
  </div>
</navbar>

      
      <div class="sidebar-mask" @click="toggleSidebar(false)">
      </div>
        <sidebar @toggle-sidebar="toggleSidebar">
          
          <navlinks>
            



            
          </navlinks><div id="searchbox" class="searchbox" role="search">
  <div class="caption"><span class="caption-text">Quick search</span>
    <div class="searchformwrapper">
      <form class="search" action="search.html" method="get">
        <input type="text" name="q" />
        <input type="submit" value="Search" />
        <input type="hidden" name="check_keywords" value="yes" />
        <input type="hidden" name="area" value="default" />
      </form>
    </div>
  </div>
</div><div class="sidebar-links" role="navigation" aria-label="main navigation">
  
    <div class="sidebar-group">
      <p class="caption">
        <span class="caption-text"><a href="index.html#welcome-to-dronebuddy-s-documentation">Contents:</a></span>
      </p>
      <ul class="">
        
          <li class="toctree-l1 ">
            
              <a href="dronebuddylib.installationguide.html" class="reference internal ">Installation Guide</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="dronebuddylib.userguide.html" class="reference internal ">User Guide</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="dronebuddylib.atoms.html" class="reference internal ">API Doc</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="dronebuddylib.developerguide.html" class="reference internal ">Developer Guide</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="dronebuddylib.codeexample.html" class="reference internal ">Sample Program</a>
            

            
          </li>

        
      </ul>
    </div>
  
</div>
        </sidebar>

      <page>
          <div class="body-header" role="navigation" aria-label="navigation">
  
  <ul class="breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
    
      <li><a href="dronebuddylib.userguide.html">User Guide</a> &raquo;</li>
    
    <li>Supported models</li>
  </ul>
  

  <ul class="page-nav">
  <li class="prev">
    <a href="dronebuddylib.userguide.intentrecognition.html"
       title="previous chapter">← Supported models</a>
  </li>
  <li class="next">
    <a href="dronebuddylib.userguide.objectdetection.html"
       title="next chapter">Supported models →</a>
  </li>
</ul>
  
</div>
<hr>
          <div class="content" role="main" v-pre>
            
  <section id="supported-models">
<h1>Supported models<a class="headerlink" href="#supported-models" title="Link to this heading">¶</a></h1>
<section id="face-recognition">
<h2>Face-recognition<a class="headerlink" href="#face-recognition" title="Link to this heading">¶</a></h2>
<p>Face-recognition is an open-source Python library that provides face detection, face alignment, and face recognition capabilities.</p>
<p>Here’s a simplified explanation of how the “face_recognition” library works:</p>
<ol class="arabic simple">
<li><p>Installation: To use the “face_recognition” library, you need to install it first. You can install it via pip by running the following command in your Python environment:</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>face_recognition
</pre></div>
</div>
<ol class="arabic simple">
<li><p>Face Detection: The library utilizes pre-trained models to detect faces in images or video frames. It can detect multiple faces in an image and return the bounding box coordinates (top, right, bottom, left) for each detected face. The detection process uses computer vision algorithms to locate the presence and location of faces.</p></li>
<li><p>Face Alignment: After face detection, the library can perform face alignment to normalize the face’s position and orientation. This helps improve the accuracy of subsequent face recognition tasks by aligning the faces to a standardized pose.</p></li>
<li><p>Feature Extraction: The library extracts facial features from the aligned face images. It employs a deep learning-based method to capture important characteristics of the face. These features are represented as numerical feature vectors that encode information about the face’s geometry, texture, and other discriminative details.</p></li>
<li><p>Face Recognition: Using the extracted feature vectors, the “face_recognition” library can perform face recognition by comparing the features of a query face with the features of known faces stored in a database. It calculates the similarity or distance between the feature vectors and determines the closest matches. You can specify a threshold to define the level of similarity required for a positive recognition.</p></li>
<li><p>Usage: To use the library, you typically load an image or video frame, detect faces, align the faces (optional), and then extract and compare the face features for recognition. The library provides easy-to-use functions and classes to perform these tasks, allowing you to integrate face recognition capabilities into your Python applications.</p></li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It’s worth noting that the “face_recognition” library is built on top of popular deep learning frameworks like dlib and OpenCV. It provides a high-level interface to simplify face recognition tasks and abstracts away the complexities of model training and implementation.</p>
</div>
<p>Remember that face recognition accuracy can be influenced by factors such as image quality, variations in lighting and pose, and the number of training examples available for known faces. Therefore, it’s important to consider these factors and perform proper testing and fine-tuning to achieve optimal results in your specific use case.</p>
<section id="dlib">
<h3>dlib<a class="headerlink" href="#dlib" title="Link to this heading">¶</a></h3>
</section>
<section id="why-do-we-need-dlib">
<h3>Why do we need dlib<a class="headerlink" href="#why-do-we-need-dlib" title="Link to this heading">¶</a></h3>
<p>dlib is a dependency that provides essential functionality for face detection and facial landmark estimation. The “face_recognition” library builds upon dlib’s capabilities to offer a higher-level interface specifically for face recognition tasks.</p>
<p>Dlib is a C++ library that contains various machine learning algorithms and tools, including the implementation of the “HOG” (Histogram of Oriented Gradients) feature descriptor and the “SVM” (Support Vector Machine) classifier. These components are used by the “face_recognition” library to perform face detection, facial landmark detection, and face alignment.</p>
<p>Here’s a breakdown of dlib’s role in the face recognition process:</p>
<ol class="arabic simple">
<li><p>Face Detection: The face detection component in dlib utilizes the “HOG” feature descriptor and the “SVM” classifier to detect faces in images. It searches for patterns in image gradients to identify regions likely to contain faces.</p></li>
<li><p>Facial Landmark Detection: Dlib provides a facial landmark estimation model, which is trained to identify key facial landmarks such as the eyes, nose, and mouth. These landmarks are crucial for face alignment and accurately extracting facial features.</p></li>
<li><p>Face Alignment: Using the detected facial landmarks, dlib performs face alignment by applying geometric transformations to normalize the face’s position, scale, and orientation. Face alignment helps ensure that subsequent face recognition tasks are robust to variations in pose and improve the accuracy of feature extraction.</p></li>
<li><p>The “face_recognition” library abstracts the usage of dlib by providing a simpler, user-friendly interface that allows developers to focus on the face recognition tasks rather than dealing with low-level details. It leverages the face detection and facial landmark estimation capabilities of dlib to provide a higher-level API for face recognition and feature extraction.</p></li>
</ol>
<p>In summary, dlib plays a critical role in providing the underlying functionality for face detection, facial landmark detection, and face alignment in the “face_recognition” library. It enables accurate and efficient face recognition by handling the low-level details of these tasks, allowing developers to work with face recognition in a more accessible manner using the “face_recognition” library.</p>
</section>
</section>
</section>


          </div>
          <div class="page-nav">
            <div class="inner"><ul class="page-nav">
  <li class="prev">
    <a href="dronebuddylib.userguide.intentrecognition.html"
       title="previous chapter">← Supported models</a>
  </li>
  <li class="next">
    <a href="dronebuddylib.userguide.objectdetection.html"
       title="next chapter">Supported models →</a>
  </li>
</ul><div class="footer" role="contentinfo">
      &#169; Copyright 2023, NUS.
    <br>
    Created using <a href="http://sphinx-doc.org/">Sphinx</a> 7.2.2 with <a href="https://github.com/schettino72/sphinx_press_theme">Press Theme</a> 0.8.0.
</div>
            </div>
          </div>
      </page>
    </div></div>
    
    
  </body>
</html>