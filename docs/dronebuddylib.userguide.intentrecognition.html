<!DOCTYPE html>
<html  lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1"><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

      <title>Supported models</title>
    
          <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
          <link rel="stylesheet" href="_static/theme.css " type="text/css" />
      
      <!-- sphinx script_files -->
        <script src="_static/documentation_options.js?v=5929fcd5"></script>
        <script src="_static/doctools.js?v=888ff710"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>

      
      <!-- bundled in js (rollup iife) -->
      <!-- <script src="_static/theme-vendors.js"></script> -->
      <script src="_static/theme.js" defer></script>
    
  <link rel="index" title="Index" href="genindex.html" />
  <link rel="search" title="Search" href="search.html" />
  <link rel="next" title="Supported models" href="dronebuddylib.userguide.facerecognition.html" />
  <link rel="prev" title="Supported models" href="dronebuddylib.userguide.voicerecognition.html" /> 
  </head>

  <body>
    <div id="app">
    <div class="theme-container" :class="pageClasses"><navbar @toggle-sidebar="toggleSidebar">
  <router-link to="index.html" class="home-link">
    
      <span class="site-name">Dronebuddy</span>
    
  </router-link>

  <div class="links">
    <navlinks class="can-hide">



    </navlinks>
  </div>
</navbar>

      
      <div class="sidebar-mask" @click="toggleSidebar(false)">
      </div>
        <sidebar @toggle-sidebar="toggleSidebar">
          
          <navlinks>
            



            
          </navlinks><div id="searchbox" class="searchbox" role="search">
  <div class="caption"><span class="caption-text">Quick search</span>
    <div class="searchformwrapper">
      <form class="search" action="search.html" method="get">
        <input type="text" name="q" />
        <input type="submit" value="Search" />
        <input type="hidden" name="check_keywords" value="yes" />
        <input type="hidden" name="area" value="default" />
      </form>
    </div>
  </div>
</div><div class="sidebar-links" role="navigation" aria-label="main navigation">
  
    <div class="sidebar-group">
      <p class="caption">
        <span class="caption-text"><a href="index.html#welcome-to-dronebuddy-s-documentation">Contents:</a></span>
      </p>
      <ul class="">
        
          <li class="toctree-l1 ">
            
              <a href="dronebuddylib.installationguide.html" class="reference internal ">Installation Guide</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="dronebuddylib.userguide.html" class="reference internal ">User Guide</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="dronebuddylib.atoms.html" class="reference internal ">API Doc</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="dronebuddylib.developerguide.html" class="reference internal ">Developer Guide</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="dronebuddylib.codeexample.html" class="reference internal ">Sample Program</a>
            

            
          </li>

        
      </ul>
    </div>
  
</div>
        </sidebar>

      <page>
          <div class="body-header" role="navigation" aria-label="navigation">
  
  <ul class="breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
    
      <li><a href="dronebuddylib.userguide.html">User Guide</a> &raquo;</li>
    
    <li>Supported models</li>
  </ul>
  

  <ul class="page-nav">
  <li class="prev">
    <a href="dronebuddylib.userguide.voicerecognition.html"
       title="previous chapter">← Supported models</a>
  </li>
  <li class="next">
    <a href="dronebuddylib.userguide.facerecognition.html"
       title="next chapter">Supported models →</a>
  </li>
</ul>
  
</div>
<hr>
          <div class="content" role="main" v-pre>
            
  <section id="supported-models">
<h1>Supported models<a class="headerlink" href="#supported-models" title="Link to this heading">¶</a></h1>
<section id="snips-nlu">
<h2>SNIPS NLU<a class="headerlink" href="#snips-nlu" title="Link to this heading">¶</a></h2>
<p>Snips NLU (Natural Language Understanding) is an open-source library designed to perform intent recognition and slot filling, two essential tasks in natural language processing. It allows computers to understand the meaning and extract relevant information from user queries or commands.</p>
<ol class="arabic simple">
<li><p>Training Data: Snips NLU requires training data to learn how to understand and process user queries. Training data consists of labeled examples, including user queries and their corresponding intents and slots. Intents represent the user’s intention, while slots capture specific pieces of information within the query.</p></li>
<li><p>Intent Recognition: Snips NLU uses machine learning algorithms to train a model on the provided training data. During training, the model learns to recognize different intents by analyzing the patterns and relationships between the words or features in the queries and their corresponding intents. The trained model can then predict the intent of new, unseen queries.</p></li>
<li><p>Slot Filling: In addition to intent recognition, Snips NLU also performs slot filling. Slot filling involves identifying and extracting specific information or parameters (slots) from the user’s query. For example, in the query “Book a table for two at 7 PM,” the slots could be “table” (slot type: restaurant table) and “time” (slot type: time). Snips NLU learns to recognize and extract these slots based on the patterns observed in the training data.</p></li>
<li><p>Model Deployment: Once the model is trained, it can be deployed and integrated into your application or system. Snips NLU provides a simple API that allows you to send user queries to the model and receive the recognized intent and extracted slots as the output.</p></li>
<li><p>Intent Recognition and Slot Filling in Action: When a user query is sent to the deployed Snips NLU model, it processes the text and predicts the intent based on the learned patterns. Additionally, it identifies and extracts relevant slots from the query, providing structured information about the user’s request.</p></li>
<li><p>Output Generation: The recognized intent and extracted slots are generated as output, enabling your application to understand the user’s intention and access the specific information provided in the query. This output can be further processed to trigger appropriate actions or provide relevant responses based on the recognized intent and slots.</p></li>
</ol>
<p>Snips NLU is designed to be flexible and customizable, allowing you to train models specific to your domain or application. It provides tools to annotate training data, train the models, and evaluate their performance.</p>
<p>By using Snips NLU, you can incorporate natural language understanding capabilities into your applications, such as chatbots, voice assistants, or any system that requires understanding and processing of user queries.</p>
</section>
<section id="chat-gpt">
<h2>Chat GPT<a class="headerlink" href="#chat-gpt" title="Link to this heading">¶</a></h2>
<p>DroneBuddy is integrating ChatGPT for intent resolution. This section explores the role of ChatGPT in DroneBuddy, highlighting its capabilities, features, and integration process. For more comprehensive details about ChatGPT, refer to OpenAI’s official documentation.</p>
<ol class="arabic simple">
<li><p>Language Understanding: ChatGPT is adept at interpreting natural language inputs in DroneBuddy. It analyzes user queries or commands to discern the underlying intents, essential for providing accurate responses or actions.</p></li>
<li><p>Contextual Awareness: A key strength of ChatGPT in DroneBuddy is its ability to maintain context throughout a conversation. This ensures understanding of follow-up queries or references to previous parts of the dialogue, enhancing the user experience.</p></li>
<li><p>Response Generation: In DroneBuddy, ChatGPT is tasked with generating human-like, coherent responses that are contextually appropriate and informative, based on the user’s intent.</p></li>
<li><p>Continuous Learning: While ChatGPT comes pre-trained on extensive textual data, DroneBuddy can fine-tune it for specific domains or applications, improving its effectiveness and relevance.</p></li>
</ol>
<section id="important-considerations">
<h3>Important Considerations<a class="headerlink" href="#important-considerations" title="Link to this heading">¶</a></h3>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>It’s crucial to remember that ChatGPT, as implemented in DroneBuddy, generates responses based on learned data patterns and probabilities. Therefore, its output might not always be perfectly accurate or suitable for every situation. Continuous monitoring and occasional fine-tuning are recommended to ensure the system aligns with DroneBuddy’s specific needs and provides optimal results.</p>
</div>
</section>
</section>
</section>


          </div>
          <div class="page-nav">
            <div class="inner"><ul class="page-nav">
  <li class="prev">
    <a href="dronebuddylib.userguide.voicerecognition.html"
       title="previous chapter">← Supported models</a>
  </li>
  <li class="next">
    <a href="dronebuddylib.userguide.facerecognition.html"
       title="next chapter">Supported models →</a>
  </li>
</ul><div class="footer" role="contentinfo">
      &#169; Copyright 2023, NUS.
    <br>
    Created using <a href="http://sphinx-doc.org/">Sphinx</a> 7.2.2 with <a href="https://github.com/schettino72/sphinx_press_theme">Press Theme</a> 0.8.0.
</div>
            </div>
          </div>
      </page>
    </div></div>
    
    
  </body>
</html>